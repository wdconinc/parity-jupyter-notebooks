{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RzTChW53KAdV"
   },
   "source": [
    "# Finding Best Linear Regresssion Sets In Single Pass Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJyolq12DYm7"
   },
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqNouFd1J7gF"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnY_R32NKLtg"
   },
   "source": [
    "## Create Test Data Set With Random Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QnUy6aqxDhPw"
   },
   "source": [
    "### Choose Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1543203350533,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "DIAHbY9VKPJ4",
    "outputId": "c5488a89-72fb-47ad-b067-5f44275924b7"
   },
   "outputs": [],
   "source": [
    "# number of dependent variables\n",
    "M = np.random.randint(10, 15)\n",
    "# number of independent variables\n",
    "N = np.random.randint(10, 15)\n",
    "# number of larger correlations between dependent and independent\n",
    "K = np.random.randint(2, min(M,N))\n",
    "\n",
    "print(\"Using %d independent variables with %d large correlations, %d dependent variables\" % (N,K,M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lu8MKkq8WZyQ"
   },
   "source": [
    "### Create Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaL-HymADzbn"
   },
   "source": [
    "If we start from $Z$, a column of independently and normally distributed random variables, then we can construct $X$, a column of correlated and normally distributed random variables with covariance matrix $\\Sigma$ as follows:\n",
    "- find the Cholesky decomposition of $\\Sigma$ (positive-definite) into an upper triangular $C$:\n",
    "$$ \\Sigma = C^T C $$\n",
    "- apply Cholesky matrix to $Z$:\n",
    "$$ X = C^T Z $$\n",
    "\n",
    "Reference: http://www.columbia.edu/~mh2078/MonteCarlo/MCS_Generate_RVars.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y0lTEbx2Wb9n"
   },
   "source": [
    "We can also write $\\Sigma$ in terms of the matrix of correlation coefficients $\\mathrm{Corr}[X]$, where the diagonal elements will be ones and the off-diagonal elements between -1 and +1:\n",
    "\\begin{align}\n",
    "\\Sigma & = Cov[X] \\\\ \n",
    "& = Diag[Var(X)]^\\frac{1}{2} \\, Corr[X] \\, Diag[Var(X)]^\\frac{1}{2} \\\\\n",
    "& = Diag[\\Sigma]^\\frac{1}{2} \\, Corr[X] \\, Diag[\\Sigma]^\\frac{1}{2} \\\\\n",
    "& = \\sigma \\, R \\, \\sigma\n",
    "\\end{align}\n",
    "\n",
    "We will use the [covariance matrix in block form](https://en.wikipedia.org/wiki/Covariance_matrix#Block_matrices).\n",
    "$$ \\Sigma = \\Big[ \\begin{array}{cc} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array}\\Big] $$\n",
    "and\n",
    "$$ R = \\Big[ \\begin{array}{cc} R_{XX} & R_{XY} \\\\ R_{YX} & R_{YY} \\end{array}\\Big] $$\n",
    "with $X$ the so-called independent variables and $Y$ the so-called dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1543203362177,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "uKPJv3RMXbpm",
    "outputId": "ccfc0732-7fc1-4402-a50c-1e894c355d7a"
   },
   "outputs": [],
   "source": [
    "# Construct diagonal of Sigma\n",
    "diag0 = np.diag(0.1 + np.random.randn(M + N) * 0.01)\n",
    "\n",
    "# Construct random correlation matrix\n",
    "corr0 = np.random.randn(N+M, N+M) * 0.01 # normal at 1% level\n",
    "corr0[:N,:N] = np.random.randn(N, N) * 0.1 # normal at 10% level\n",
    "corr0[N:,N:] = np.random.randn(M, M) * 0.1 # normal at 10% level\n",
    "corr0[:K,:K] = (np.random.rand(K, K) * 2 - 1) # uniform between -1 and +1\n",
    "corr0[:K,N:] = (np.random.rand(K, M) * 2 - 1) # uniform between -1 and +1\n",
    "np.fill_diagonal(corr0, 1) # diagonal is 1\n",
    "corr0 = (corr0 + corr0.T) / 2 # symmetrize\n",
    "corr0 = corr0 @ corr0.T # positive definite\n",
    "\n",
    "# Make sure correlation matrix is normalized\n",
    "norm0 = np.diag(np.sqrt(np.diag(corr0))**-1)\n",
    "corr0 = norm0 @ corr0 @ norm0\n",
    "corr0 = (corr0 + corr0.T) / 2.0\n",
    "\n",
    "# Determine covariance\n",
    "cov0 = diag0 @ corr0 @ diag0\n",
    "\n",
    "# Plot correlation matrix\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].matshow(corr0, cmap = \"hot_r\")\n",
    "\n",
    "# Cholesky decomposition (returns *lower* triangular matrix)\n",
    "C = np.linalg.cholesky(cov0)\n",
    "ax[1].matshow(C, cmap = \"hot_r\") \n",
    "np.testing.assert_allclose(C @ C.T, cov0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HERFBUj2Vgfo"
   },
   "source": [
    "### Create Correlated Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1530,
     "status": "ok",
     "timestamp": 1543178540875,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "tuT2gHXhKa9S",
    "outputId": "04765738-7c32-402f-b93f-1bb53b6965f7"
   },
   "outputs": [],
   "source": [
    "# Number of measurements\n",
    "n = 1000000\n",
    "\n",
    "# Create X and Y\n",
    "Z = np.random.randn(N + M, n)\n",
    "XY = C @ Z\n",
    "X = XY[:N]\n",
    "Y = XY[N:]\n",
    "\n",
    "# Plot some data\n",
    "plt.matshow(XY[:,:200], cmap = \"hot_r\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1543178551878,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "fM_1JtxlRzbA",
    "outputId": "13b95c6e-9eee-4636-e88b-64a6e52d6b4f"
   },
   "outputs": [],
   "source": [
    "cov = np.cov(XY)\n",
    "corr = np.corrcoef(XY)\n",
    "\n",
    "fig, ax = plt.subplots(2,3)\n",
    "ax[0,0].matshow(cov, cmap = \"hot_r\")\n",
    "ax[0,1].matshow(cov0, cmap = \"hot_r\")\n",
    "ax[0,2].matshow(cov0 - cov, cmap = \"hot_r\")\n",
    "np.testing.assert_allclose(cov0, cov, atol = 0.2 * np.average(cov))\n",
    "\n",
    "ax[1,0].matshow(corr, cmap = \"hot_r\")\n",
    "ax[1,1].matshow(corr0, cmap = \"hot_r\")\n",
    "ax[1,2].matshow(corr0 - corr, cmap = \"hot_r\")\n",
    "np.testing.assert_allclose(corr0, corr, atol = 0.2 * np.average(corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dlkJvPw8XEh5"
   },
   "source": [
    "## Determine Summary Statistics Before Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1543178617680,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "LWfJZLXJS-D7",
    "outputId": "d2a2a339-1e6b-4209-e8de-68262bccf374"
   },
   "outputs": [],
   "source": [
    "means = np.mean(XY, axis = 1)\n",
    "dmeans = np.sqrt(vars) / np.sqrt(n)\n",
    "vars = np.var(XY, axis = 1)\n",
    "\n",
    "# Plot means and variances\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].errorbar(range(len(means)), means, dmeans, fmt = 'o')\n",
    "ax[1].errorbar(range(len(vars)), vars, fmt = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZtxBhBtXJbz"
   },
   "source": [
    "## Calculate Corrected Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2F92RFnuFS6U"
   },
   "source": [
    "#### Model\n",
    "We hypothesize that the observed values for $Y$ are related to the observed values for $X$ by\n",
    "$$ Y = Y' + X A_{XY} + \\epsilon $$\n",
    "in the presence of the normally distribute noise $\\epsilon = \\mathcal{N}(0, \\sigma_Y^2 I)$. \n",
    "\n",
    "We wish to determine the underlying $E[Y']$ and $Cov[XY']$ from the observed $E[Y]$ and $Cov[XY]$. We wish to determine an estimator $\\hat{A}_{XY}$ and a statistical test to determine how many parameters $p$ in $X$ should be included (i.e. for which $p$ is the null hypothesis of the observed dependence allowed for $p-1$ parameters excluded at a certain probability)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T2slq3cyFVWn"
   },
   "source": [
    "#### Covariance and Correlation Matrices\n",
    "The regression corrections are determined for the observed correlation matrix $R$, covariance matrix $\\Sigma$, and diagonal matrix $\\sigma$ of standard deviations.\n",
    "\n",
    "$$ \\Sigma = \\Big[ \\begin{array}{cc} \\Sigma_{XX} & \\Sigma_{XY} \\\\ \\Sigma_{YX} & \\Sigma_{YY} \\end{array}\\Big] = \\Big[ \\begin{array}{cc} \\sigma_X & 0 \\\\ 0 & \\sigma_Y\\end{array} \\Big] \\Big[ \\begin{array}{cc} R_{XX} & R_{XY} \\\\ R_{YX} & R_{YY} \\end{array}\\Big] \\Big[ \\begin{array}{cc} \\sigma_X & 0 \\\\ 0 & \\sigma_Y\\end{array} \\Big] = \\sigma R \\sigma $$\n",
    "\n",
    "with the indepedent and dependent variable covariance and correlation matrices\n",
    "$$ \\Sigma_{XX} = \\sigma_X R_{XX} \\sigma_X $$\n",
    "$$ \\Sigma_{XY} = \\sigma_X R_{XY} \\sigma_Y $$\n",
    "$$ \\Sigma_{YY} = \\sigma_Y R_{YY} \\sigma_Y $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ki_zIDR96Pnj"
   },
   "source": [
    "#### Removing Correlations Between $Y'$ and $X$\n",
    "We wish to determine $A_{XY}$ such that the corrected dependent variables\n",
    "$$ Y' = Y - X A_{XY} $$\n",
    "are uncorrelated with $X$. This occurs when their cross covariance matrix is zero:\n",
    "$$ Cov[X,Y'] = E[(X - E[X])(Y' - E[Y'])] = 0 $$\n",
    "\n",
    "We can expand this and solve for $A_{XY}$:\n",
    "\\begin{align}\n",
    "E[(X - E[X])(Y - XA_{XY} - E[Y] + E[X] A_{XY})] & = 0 \\\\\n",
    "E[(X - E[X])(Y - E[Y])] - E[(X - E[X])(X - E[X])] A_{XY} & = 0 \\\\\n",
    "Cov[X,Y] - Var[X] A_{XY} & = 0 \\\\\n",
    "\\Sigma_{XY} - \\Sigma_{XX} A_{XY} & = 0\n",
    "\\end{align}\n",
    "\n",
    "The solution occurs for a specific $\\hat{A}_{XY}$:\n",
    "$$ \\hat{A}_{XY} = \\Sigma_{XX}^{-1} \\Sigma_{XY} $$\n",
    "which exists when the inverse of $\\Sigma_{XX}$ exists, or when there are no linearly related variables in the set of independent variables $X$.\n",
    "\n",
    "We can write this in terms of correlation matrices as well (this is the notation that is used in Qweak linear regression):\n",
    "$$ \\hat{A}_{XY} = \\Sigma_{XX}^{-1} \\Sigma_{XY} = (\\sigma_X^{-1} R_{XX}^{-1} \\sigma_X^{-1}) (\\sigma_X R_{XY} \\sigma_Y) =\\sigma_X^{-1} R_{XX}^{-1} R_{XY} \\sigma_Y $$\n",
    "\n",
    "In this case the mean and variance just become\n",
    "\\begin{align}\n",
    "E[Y'] & = E[Y] - E[X] \\hat{A}_{XY} \\\\\n",
    "Var[Y'] & = E[(Y' - E[Y'])^2] \\\\ & = E[(Y - X \\hat{A}_{XY} - E[Y] + E[X] \\hat{A}_{XY})^2] \\\\ & = E[(Y - E[Y]) - (X - E[X])\\hat{A}_{XY})^2] \\\\ & = Cov[Y] + Cov[X\\hat{A}_{XY}] - 2 Cov[X,Y] \\hat{A}_{XY} \\\\ & = Cov[Y] + \\hat{A}_{YX} Cov[X] \\hat{A}_{XY} - 2 Cov[X,Y] \\hat{A}_{XY} \\\\\n",
    "& = \\Sigma_{YY} + \\hat{A}_{YX} \\Sigma_{XX} \\hat{A}_{XY} - 2 \\Sigma_{YX} \\hat{A}_{XY}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fG2yJkpTFhxe"
   },
   "source": [
    "#### Uncertainty on Regression Coefficients\n",
    "To obtain the uncertainty on the regression coefficients, we introduce a normally distributed noise variable $\\epsilon = \\mathcal{N}(0,\\sigma^2)$ on $Y$ such that:\n",
    "$$ Y = X A_{XY} + \\epsilon = X A_{XY} +\\mathcal{N}(0,\\sigma_Y^2) $$\n",
    "\n",
    "If we write\n",
    "\\begin{align}\n",
    "\\hat{A}_{XY} & = \\Sigma_{XX}^{-1} \\Sigma_{XY} \\\\\n",
    "& = E[(X^T X)^{-1}] E[(X^T Y)] \\\\\n",
    "& = E[(X^T X)^{-1}] E[(X^T (X A_{XY} + \\epsilon)] \\\\\n",
    "& = A_{XY} + E[(X^T X)^{-1}] E[(X^T e)] \\\\\n",
    "& = \\mathcal{N}(A_{XY}, E[(X^T X)^{-1}] E[(X^T \\sigma_Y^2)]\n",
    "\\end{align}\n",
    "\n",
    "This then becomes, on the diagonal:\n",
    "$$ \\Delta A_{XY} = \\Sigma_{XX}^{-1}  $$ FIXME\n",
    "\n",
    "Somehow LinRegBlue claims that the uncertainty on $A_{XY}$ is given by\n",
    "$$ \\Delta A_{XY} = \\sigma_X^{-1} R_{XX}^{-1} \\sigma_{Y'} / \\sqrt{ndof} $$\n",
    "\n",
    "FIXME: I think there should be an entire $M \\times M$ covariance matrix for the $M$ sensitivities in $A_{XY}$ for each of the $N$ dependent variables $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1543178703280,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "JnI0Om1IXUAO",
    "outputId": "fd5c4941-cde3-4880-b40d-020cafce955d"
   },
   "outputs": [],
   "source": [
    "# Independent covariances and standard deviations\n",
    "Sigma_XX = cov[:N,:N]\n",
    "Sigma_X = np.diag(np.sqrt(np.diag(Sigma_XX)))\n",
    "Sigma_XX_Inv = np.linalg.inv(Sigma_XX)\n",
    "Sigma_X_Inv = np.linalg.inv(Sigma_X)\n",
    "R_XX = corr[:N,:N]\n",
    "R_XX_Inv = np.linalg.inv(R_XX)\n",
    "np.testing.assert_allclose(Sigma_X @ R_XX @ Sigma_X, Sigma_XX)\n",
    "\n",
    "# Dependent covariances and standard deviations\n",
    "Sigma_YY = cov[N:,N:]\n",
    "Sigma_Y = np.diag(np.sqrt(np.diag(Sigma_YY)))\n",
    "Sigma_Y_Inv = np.linalg.inv(Sigma_Y)\n",
    "R_YY = corr[N:,N:]\n",
    "np.testing.assert_allclose(Sigma_Y @ R_YY @ Sigma_Y, Sigma_YY)\n",
    "\n",
    "# Cross correlations\n",
    "Sigma_XY = cov[:N,N:]\n",
    "R_XY = corr[:N,N:]\n",
    "np.testing.assert_allclose(Sigma_X @ R_XY @ Sigma_Y, Sigma_XY)\n",
    "\n",
    "# Sensitivities\n",
    "A_XY = Sigma_XX_Inv @ Sigma_XY\n",
    "A_YX = A_XY.T\n",
    "\n",
    "# Uncertainties\n",
    "Sigma_YpYp = Sigma_Y @ Sigma_Y + A_YX @ Sigma_XX @ A_XY - 2 * A_YX @ Sigma_XY\n",
    "sigma_Yp = np.sqrt(np.diag(Sigma_YpYp))\n",
    "ndof = n - N - 1\n",
    "# FIXME\n",
    "dA_XY = np.outer(np.sqrt(np.diag(R_XX_Inv)) * np.diag(Sigma_X_Inv), 1 / (sigma_Yp * np.sqrt(ndof)))\n",
    "dA_YX = dA_XY.T\n",
    "\n",
    "# Plot sensitivities\n",
    "fig, ax = plt.subplots(1,4,sharey = True)\n",
    "ax[0].matshow(Sigma_XY.T)\n",
    "ax[0].set_xlabel(\"independent\")\n",
    "ax[0].set_ylabel(\"dependent\")\n",
    "ax[0].set_title(\"Cov\")\n",
    "ax[1].matshow(A_YX)\n",
    "ax[1].set_xlabel(\"independent\")\n",
    "ax[1].set_title(\"A\")\n",
    "ax[2].matshow(dA_YX)\n",
    "ax[2].set_xlabel(\"independent\")\n",
    "ax[2].set_title(\"$\\\\Delta$A\")\n",
    "ax[3].matshow(dA_YX / A_YX)\n",
    "ax[3].set_xlabel(\"independent\")\n",
    "ax[3].set_title(\"$\\\\Delta$A / A\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpgKSnq4ulQA"
   },
   "outputs": [],
   "source": [
    "# Setup correction on copy\n",
    "XY_c = XY.copy()\n",
    "X_c = XY_c[:N]\n",
    "Y_c = XY_c[N:]\n",
    "\n",
    "# Apply correction\n",
    "Y_c -= A_YX @ X_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d2PG395ulFg"
   },
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "cov_c = np.cov(XY_c)\n",
    "corr_c = np.corrcoef(XY_c)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].matshow(cov_c, cmap = \"hot_r\")\n",
    "ax[1].matshow(corr_c, cmap = \"hot_r\")\n",
    "\n",
    "# assert zero blocks (atol since rtol useless when second argument is zero)\n",
    "np.testing.assert_allclose(cov_c[:N,N:], 0, atol = 1e-7)\n",
    "np.testing.assert_allclose(cov_c[N:,:N], 0, atol = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1543178740122,
     "user": {
      "displayName": "Wouter Deconinck",
      "photoUrl": "https://lh3.googleusercontent.com/-8U7EnQnXx24/AAAAAAAAAAI/AAAAAAAAfYY/0z4vlg0mssc/s64/photo.jpg",
      "userId": "15364288060950973292"
     },
     "user_tz": 300
    },
    "id": "CoJZZPTymS1y",
    "outputId": "ca9130a0-8d50-400f-f399-a0243c637110"
   },
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "means_c = np.mean(XY_c, axis = 1)\n",
    "vars_c = np.var(XY_c, axis = 1)\n",
    "dmeans_c = np.sqrt(vars_c) / np.sqrt(n)\n",
    "\n",
    "# Plot means and variances\n",
    "fig,ax = plt.subplots(1,2)\n",
    "ax[0].errorbar(range(len(means_c)), means_c, dmeans_c, fmt = 'or')\n",
    "ax[0].errorbar(range(len(means)), means, dmeans, fmt = 'ob')\n",
    "ax[1].errorbar(range(len(vars_c)), vars_c, fmt = 'or')\n",
    "ax[1].errorbar(range(len(vars)), vars, fmt = 'ob')\n",
    "plt.show()\n",
    "\n",
    "np.testing.assert_less_or_equal(vars_c[N:], vars[N:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9R2OWQrOGE4q"
   },
   "source": [
    "#### Testing for Agreement With Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0O_WflAat88g"
   },
   "outputs": [],
   "source": [
    "# correction of the means\n",
    "np.testing.assert_allclose(means[N:] - A_YX @ means[:N], means_c[N:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gLdO94Pvv3O"
   },
   "outputs": [],
   "source": [
    "# correction of the new covariances\n",
    "np.testing.assert_allclose(cov[N:,N:] + A_YX @ cov[:N,:N] @ A_XY - 2 * A_YX @ cov[:N,N:], cov_c[N:,N:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEsop7MsvxMx"
   },
   "outputs": [],
   "source": [
    "# correction of the new variances\n",
    "np.testing.assert_allclose(sigma_Yp**2, vars_c[N:], rtol = 1e-4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Finding Best Regression Sets in Single Pass Analysis.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
